# Copyright 2011 Splunk Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

### hadoop general

[hadoop_startup_msg]
search = hadoop STARTUP_MSG 

[hadoop_shutdown_msg]
search = hadoop SHUTDOWN_MSG 

#[hadoop_info]
#search = hadoop severity=INFO

#[hadoop_warn]
#search = hadoop severity=WARN

#[hadoop_error]
#search = hadoop severity=ERROR

#[hadoop_fatal]
#search = hadoop severity=FATAL

#[hadoop_exception]
#search = hadoop severity=ERROR exception

#[hadoop_traceback]
#search = hadoop severity=ERROR OR severity=WARN linecount>2

[hadoop_rpc_shutdown]
search = hadoop "RpcInstrumentation: shut down"

[hadoop_tasktracker_mapred_shutdown]
search = hadoop "Shutting down: Map-events fetcher for all reduce tasks" 

[hadoop_tasktracker_reinint_received]
search = hadoop "Received RenitTrackerAction"

[hadoop_tasktracker_reinit]
search = hadoop "Reinitializing local state"

[hadoop_file_cache_size]
search = hadoop "FILE_CACHE_SIZE for mapOutputServlet set"

[hadoop_index_cache_created]
search = hadoop IndexCache created

[hadoop_setsid_exited_ok]
search = hadoop "setsid exited with exit code 0"

[hadoop_task_memory_manager]
search = hadoop "totalMemoryAllottedForTasks"

[hadoop_task_memory_manager_disabled]
search = hadoop "TaskMemoryManager is disabled"

[hadoop_starting_thread]
search = hadoop "TaskTracker: Starting thread:"

[hadoop_starting_tracker]
search = hadoop "TaskTracker: Starting tracker"

[hadoop_task_tracker_starting]
search = hadoop "Starting tasktracker with owner as"

[hadoop_task_tracker_up]
search = hadoop "TaskTracker up at:"

[hadoop_mem_calc_plugin]
search = hadoop "Using MemoryCalculatorPlugin"

[hadoop_resource_calc_plugin]
search = hadoop "Using ResourceCalculatorPlugin"

[hadoop_log_truncator_starting]
search = hadoop "Initializing logs' truncater"

[hadoop_native_library_loaded]
search = hadoop "Loaded the native-hadoop library"

[hadoop_mapred_local_dir_location]
search = hadoop "mapred local directories are"

[hadoop_resending_status]
search = hadoop "Resending 'status' to"

### namenode

[hadoop_unable_to_place_enough_replicas]
search = hadoop "Not able to place enough replicas, still in need of"

[hadoop_no_such_user]
search = hadoop "no such user"

[hadoop_process_report]
search = hadoop "NameSystem.processReport:"

[hadoop_roll_fsimage]
search = hadoop "Roll FSImage from"

[hadoop_roll_edit_log]
search = hadoop "Roll Edit Log from"

[hadoop_name_system_transactions_syncs]
search = hadoop "Number of transactions" "Number of syncs"

[hadoop_complete_file_closed]
search = hadoop "NameSystem.completeFile: file" "is closed by"

[hadoop_lease_removing]
search = hadoop "StateChange: Removing lease on"

[hadoop_stored_block_added]
search = hadoop "NameSystem.addStoredBlock"

[hadoop_replication_requested]
search = hadoop "StateChange: BLOCK* ask" "to replicate blk_*"

[hadoop_delete_requested]
search = hadoop "StateChange: BLOCK* ask" "to delete"

[hadoop_no_blocks_found_lease_removed]
search = hadoop "internalReleaseLease: No blocks found, lease removed for"

[hadoop_lease_recovering]
search = hadoop "FSNamesystem: Recovering lease"

[hadoop_lease_expired]
search = hadoop "LeaseManager: Lease" "has expired"

[hadoop_permission_denied]
search = hadoop "AccessControlException: Permission denied"

[hadoop_invalid_block_added]
search = hadoop "NameSystem.addToInvalidates:" "is added to invalidSet" 

[hadoop_block_sync_committed]
search = hadoop commitBlockSynchronization NOT successful

[hadoop_block_sync_success]
search = hadoop commitBlockSynchronization successful

[hadoop_rename_failed]
search = hadoop "unprotectedRenameTo: failed to rename"

[hadoop_block_recovery_started]
search = hadoop "BLOCK* blk_* recovery started"

[hadoop_block_allocation]
search = hadoop "NameSystem.allocateBlock"

[hadoop_lease_not_found]
search = hadoop "LeaseExpiredException: No lease on"

[hadoop_priviledged_action_exception]
search = hadoop PriviledgedActionException

[hadoop_invalidate_queue_stats]
search = hadoop "InvalidateQueue QueueProcessingStatistics:"

[hadoop_replicate_queue_stats]
search = hadoop "ReplicateQueue QueueProcessingStatistics:"

[hadoop_block_over_replicated_count]
search = hadoop "Number of over-replicated blocks" OR "Number of  over-replicated blocks" 

[hadoop_block_under_replicated_count]
search = hadoop "UnderReplicatedBlocks has" OR "Number of under-replicated blocks"

[hadoop_block_invalid_count]
search = hadoop "Number of invalid blocks"

[hadoop_block_total_count]
search = hadoop "Total number of blocks"

[hadoop_network_topology_state]
search = hadoop "Network topology has"

[hadoop_safe_mode_disabled]
search = hadoop "Safe mode is OFF"

[hadoop_safe_mode_enabled]
search = hadoop "Safe mode ON"

[hadoop_safe_mode_extended]
search = hadoop "Safe mode extension entered"

[hadoop_safe_mode_leaving]
search = hadoop "Leaving safe mode after"

[hadoop_safe_mode_termination]
search = hadoop "Safe mode termination"

[hadoop_safe_mode_caused_delete_failure]
search = hadoop "Name node is in safe mode" "Cannot delete"

[hadoop_data_node_registered]
search = hadoop "NameSystem.registerDatanode: node registration from"

[hadoop_name_node_web_server_started]
search = hadoop "NameNode: Web-server up at"

[hadoop_name_node_up]
search = hadoop "Namenode up at"

[hadoop_fsimage_finished_loading]
search = hadoop "Finished loading FSImage in"

[hadoop_name_cache_init]
search = hadoop "NameCache: initialized with"

[hadoop_image_file_saved]
search = hadoop "Storage: Image file of size" saved

[hadoop_image_file_loaded]
search = hadoop "Storage: Image file of size" loaded 

[hadoop_edits_file_loaded]
search = hadoop "Storage: Edits file" loaded

[hadoop_storage_file_count]
search = hadoop "Storage: Number of files ="

[hadoop_file_name_caching]
search = hadoop "NameNode: Caching file names occuring more than"

[hadoop_storage_files_under_construction]
search = hadoop "Storage: Number of files under construction"

[hadoop_name_node_beans_registered]
search = hadoop "FSNamesystem: Registered FSNamesystemStateMBean and NameNodeMXBean"

[hadoop_access_token_settings]
search = hadoop "FSNamesystem: isAccessTokenEnabled"

[hadoop_dfs_block_invalidate_limit]
search = hadoop "FSNamesystem: dfs.block.invalidate.limit=" 

[hadoop_permission_setting]
search = hadoop "FSNamesystem: isPermissionEnabled="

[hadoop_supergroup_setting]
search = hadoop "FSNamesystem: supergroup="

[hadoop_fs_owner_setting]
search = hadoop "FSNamesystem: fsOwner="

[hadoop_gset_settings]
search = hadoop "GSet:"

[hadoop_name_system_init_failed]
search = hadoop "FSNamesystem: FSNamesystem initialization failed"

[hadoop_inconsistent_state_detected]
search = hadoop "InconsistentFSStateException: Directory" "is in an inconsistent state"

[hadoop_directory_does_not_exist]
search = hadoop "Storage: Storage directory" "does not exist"

[hadoop_data_node_incorrect_version]
search = hadoop "IncorrectVersionException: Unexpected version of data node"

[hadoop_fs_image_incorrect_version]
search = hadoop "File system image contains an old layout version"

[hadoop_removing_node]
search = hadoop "NetworkTopology: Removing a node:"

[hadoop_null_pointer_exception]
search = hadoop "java.lang.NullPointerException"

[hadoop_no_such_method_exception]
search = hadoop "java.lang.NoSuchMethodException"

[hadoop_closed_channel_exception]
search = hadoop "java.nio.channels.ClosedChannelException"

[hadoop_ipc_server_responder_call_output_error]
search = hadoop "Server: IPC Server Responder, call" "output error"

[hadoop_replication_factor_increasing]
search = hadoop "FSNamesystem: Increasing replication for file"

[hadoop_recent_invalidate_added]
search = hadoop "NameSystem.chooseExcessReplicates:" "is added to recentInvalidateSets"

[hadoop_block_invalidate]
search = hadoop "StateChange: DIR* NameSystem.invalidateBlock:" 

[hadoop_block_corrupt_replica_added]
search = hadoop "BLOCK NameSystem.addToCorruptReplicasMap:"

[hadoop_corrupt_replica_marked]
search = hadoop "FSNamesystem: Mark new replica" corrupt

[hadoop_block_inconsistent_size]
search = hadoop "FSNamesystem: Inconsistent size for block"

[hadoop_lost_heartbeat]
search = hadoop "heartbeatCheck: lost heartbeat from"

[hadoop_block_replication_monitor_timeout]
search = hadoop "FSNamesystem: PendingReplicationMonitor timed out"

### hadoop metrics2

[hadoop_metrics_mbean_registered]
search = hadoop MetricsSourceAdapter "Mbean for source" registered

[hadoop_metrics_system_started]
search = hadoop "metrics system started"

[hadoop_metrics_system_snapshot_period]
search = hadoop "scheduled snapshot period at" 

[hadoop_metrics_sink_file_started]
search = hadoop "sink file started"

[hadoop_metrics_loaded_properties]
search = hadoop "MetricsConfig: loaded properties from"

[hadoop_metrics_source_already_exists]
search = hadoop "MetricsSystemImpl: Source name" "already exists"

[hadoop_metrics_instance_not_found]
search = hadoop metrics2 "InstanceNotFoundException"

### ipc

[hadoop_ipc_server_stopping]
search = hadoop "Stopping server on" 

[hadoop_ipc_server_handler_starting]
search = hadoop "IPC Server handler" starting

[hadoop_ipc_server_handler_stopping]
search = hadoop "IPC Server handler" exiting 

[hadoop_ipc_server_responder_starting]
search = hadoop "IPC Server responder: starting"

[hadoop_ipc_server_responder_stopping]
search = hadoop "Stopping IPC Server Responder"

[hadoop_ipc_server_listener_starting]
search = hadoop "IPC Server listener" starting

[hadoop_ipc_server_listener_stopping]
search = hadoop "Stopping IPC Server listener"

[hadoop_ipc_server_socket_reader_starting]
search = hadoop "Starting SocketReader"

[hadoop_ipc_server_large_response_received]
search = hadoop "ipc.Server: Large response size" 

[hadoop_ipc_client_retrying_connect]
search = hadoop "Retrying connect to server"

[hadoop_ipc_client_version_mismatch]
search = hadoop ipc "version mismatch"

### actions

[hadoop_deleting_unknown_job]
search = hadoop "Unknown job job_*" "being deleted"

[hadoop_deleting_job_userlog_path]
search = hadoop "Deleting user log path"

[hadoop_adding_job_for_userlog_deletion]
search = hadoop Adding "for user-log deletion with"

[hadoop_received_killjob]
search = hadoop Received KillJobAction

[hadoop_purge_task]
search = hadoop "About to purge task:"

[hadoop_received_killtask]
search = hadoop Received KillTaskAction

[hadoop_add_free_slot]
search = hadoop addFreeSlot "current free slots"

[hadoop_task_output_size]
search = hadoop "reported output size"

[hadoop_task_done]
search = hadoop task "is done." 

[hadoop_task_attempt_done]
search = hadoop TaskTracker attempt_* " 1.0%"

[hadoop_task_cleanup]
search = hadoop TaskTracker cleanup

[hadoop_task_reduce_reduce]
search = hadoop TaskTracker "reduce > reduce"  

[hadoop_task_reduce_copy]
search = hadoop TaskTracker "reduce > copy"

[hadoop_task_reduce_sort]
search = hadoop TaskTracker "reduce > sort"

[hadoop_task_init]
search = hadoop TaskTracker "0.0%" NOT reduce NOT copy NOT cleanup

[hadoop_task_launch]
search = hadoop "trying to launch"

[hadoop_task_state]
search = hadoop "task's state:"

[hadoop_task_unknown_and_bad_status]
search = hadoop "Unknown child with bad" 

[hadoop_task_unknown_and_progress_status]
search = hadoop "Progress from unknown"

[hadoop_task_removed]
search = hadoop "JobTracker: Removing task"

[hadoop_exit_code]
search = hadoop "Exit code from task is"

[hadoop_launch_task_output]
search = hadoop "launchTask follows"

[hadoop_killing_process_group]
search = hadoop "Killing process group*"

[hadoop_task_no_status_killing]
search = hadoop "failed to report status for" Killing

[hadoop_task_gc_exceeded]
search = hadoop "GC overhead limit exceeded"

[hadoop_writing_commands]
search = hadoop "Writing commands to"

[hadoop_client_trace]
search = hadoop clienttrace

[hadoop_map_attempt_hdfs]
search = hadoop TaskTracker attempt "hdfs://"

[hadoop_task_output_lost]
search = hadoop "Reporting output lost" OR "Output already reported lost"

[hadoop_job_token_not_found]
search = hadoop "Can't find job token for job"

[hadoop_job_lost_tracker]
search = hadoop "JobTracker: Lost tracker"

[hadoop_task_lost_tracker]
search = hadoop "TaskInProgress: Error from" "Lost task tracker"

[hadoop_task_tracker_turned_flaky]
search = hadoop "JobInProgress: TaskTracker at" "turned 'flaky'"

[hadoop_duplicate_status_received]
search = hadoop "TaskInProgress: Recieved duplicate status update of"

[hadoop_unknown_tracker_status_received]
search = hadoop "Status from unknown Tracker"

[hadoop_job_adding_tracker]
search = hadoop "JobTracker: Adding tracker"

[hadoop_job_tracker_running]
search = hadoop "JobTracker: Starting RUNNING" 

[hadoop_decomission_nodes]
search = hadoop JobTracker Decommissioning nodes 

[hadoop_hosts_list]
search = hadoop (HostsFileReader refreshing OR setting) OR "JobTracker: Refreshing hosts information"

[hadoop_job_store_inactive]
search = hadoop "Completed job store is inactive"

[hadoop_job_history_server_addr]
search = hadoop "Job History Server web address"

[hadoop_job_history_server_started]
search = hadoop "Started job history server at"

[hadoop_job_history_file_loading]
search = hadoop "Loading Job History file"

[hadoop_job_history_logging_failed]
search = hadoop "JobHistory: Logging failed for job"

[hadoop_job_sys_dir_cleanup]
search = hadoop "Cleaning up the system directory"

[hadoop_previous_heartbeat_not_found]
search = hadoop "Serious problem, cannot find record of 'previous' heartbeat"

[hadoop_history_server_init]
search = hadoop "History server being initialized"

[hadoop_job_tracker_webserver_started]
search = hadoop "JobTracker: JobTracker webserver:"

[hadoop_job_tracker_started]
search = hadoop "JobTracker: JobTracker up at:"

[hadoop_job_tracker_starting]
search = hadoop "Starting jobtracker with owner as"

[hadoop_job_history_moving_file]
search = hadoop "JobHistory: Moving file" "to file"

[hadoop_job_done_folder_creating]
search = hadoop "Creating DONE folder at"

[hadoop_job_done_subfolder_creating]
search = hadoop "Creating DONE subfolder at"

[hadoop_job_done_subfolder_incomplete]
search = hadoop "existingDoneSubdirs doesn't contain file"

[hadoop_job_conf_deleting]
search = hadoop "Deleting localized job conf at"

[hadoop_job_retired]
search = hadoop "Retired job with id"

[hadoop_job_completed_successfully]
search = hadoop "JobInProgress: Job job_*" "has completed successfully"

[hadoop_job_summary]
search = hadoop "JobInProgress$JobSummary: "

[hadoop_job_initializing]
search = hadoop JobInProgress OR JobTracker "Initializing job_*"

[hadoop_job_init_success]
search = hadoop JobInProgress "initialized successfully with" "map tasks and" "reduce tasks"

[hadoop_job_input_and_splits]
search = hadoop "JobInProgress: Input size for job"

[hadoop_job_maps_and_reduces]
search = hadoop JobInProgress "nMaps=" "nReduces="

[hadoop_job_token_generated]
search = hadoop "JobInProgress: jobToken generated and stored"

[hadoop_job_submitted]
search = hadoop AuditLogger "OPERATION=SUBMIT_JOB" "RESULT=SUCCESS"

[hadoop_job_added]
search = hadoop JobTracker "added successfully for user"

[hadoop_job_killing]
search = hadoop JobInProgress OR JobTracker "Killing job"

[hadoop_job_aborting]
search = hadoop "JobInProgress: Aborting job"

[hadoop_task_failed_fetch]
search = hadoop "JobInProgress: Failed fetch notification"

[hadoop_too_many_fetch_failures]
search = hadoop "Too many fetch-failures"

[hadoop_task_split]
search = hadoop JobInProgress "has split on node"

[hadoop_job_locality_wait_factor]
search = hadoop "LOCALITY_WAIT_FACTOR"

[hadoop_task_completed_successfully]
search = hadoop "JobInProgress: Task 'attempt_*" "has completed task_*" successfully

[hadoop_task_failed_counter]
search = hadoop TaskInProgress "has failed" times

[hadoop_job_cleanup_task_added]
search = hadoop "JobTracker: Adding task (JOB_CLEANUP)"

[hadoop_task_cleanup_task_added]
search = hadoop "JobTracker: Adding task (TASK_CLEANUP)"

[hadoop_reduce_task_added]
search = hadoop "JobTracker: Adding task (REDUCE)"

[hadoop_map_task_added]
search = hadoop "JobTracker: Adding task (MAP)"

[hadoop_setup_task_added]
search = hadoop "JobTracker: Adding task (JOB_SETUP)"

[hadoop_choosing_rack]
search = hadoop "JobInProgress: Choosing rack"

[hadoop_choosing_data]
search = hadoop "JobInProgress: Choosing data"

[hadoop_choosing_failed_task]
search = hadoop "Choosing a failed task" 

[hadoop_task_in_debug]
search = hadoop JobTracker attempt_* "ms debug."

[hadoop_get_local_port]
search = hadoop "getLocalPort()"

[hadoop_file_system_not_ready]
search = hadoop "FileSystem is not ready yet!"

[hadoop_file_system_write_failed]
search = hadoop "JobTracker: Writing to file" "failed!"

[hadoop_filter_safety_added]
search = hadoop "Added global filtersafety"

[hadoop_scheduler_config]
search = hadoop "JobTracker: Scheduler configured with"

[hadoop_master_key_updated]
search = hadoop "Updating the current master key for generating delegation tokens"

[hadoop_expired_token_thread_starting]
search = hadoop "Starting expired delegation token remover thread"

[hadoop_task_commit_pending]
search = hadoop "is in commit-pending"

[hadoop_task_commit_received]
search = hadoop "Received commit task action for"

[hadoop_task_ignoring_update]
search = hadoop "Ignoring status-update since"

[hadoop_job_tracker_retrying]
search = hadoop "JobTracker: Retrying..."

### datanode

[hadoop_block_report_results]
search = hadoop BlockReport

[hadoop_block_report_reconciled]
search = hadoop "Reconciled asynchronous block report against current state"

[hadoop_block_scan_reconciled]
search = hadoop "Reconciled asynchronous block scan with filesystem"

[hadoop_block_scan_starting]
search = hadoop "Starting periodic block scanner"

[hadoop_block_scan_starting_new_period]
search = hadoop "DataBlockScanner: Starting a new period" 

[hadoop_block_scan_thread_exiting]
search = hadoop "DataBlockScanner: Exiting DataBlockScanner thread"

[hadoop_block_report_complete]
search = hadoop "Finished asynchronous block report scan"

[hadoop_block_report_generated]
search = hadoop "DataNode: Generated rough (lockless) block report"

[hadoop_block_report_starting]
search = hadoop "Starting asynchronous block report scan"

[hadoop_block_verification_succeeded]
search = hadoop "DataBlockScanner: Verification succeeded for"

[hadoop_block_packet_responder_terminating]
search = hadoop PacketResponder terminating

[hadoop_block_packet_responder_thread_interrupted]
search = hadoop "DataNode: PacketResponder" interrupted

[hadoop_block_received]
search = hadoop "DataNode: Received block blk_*"

[hadoop_block_receiving]
search = hadoop "DataNode: Receiving block blk_*" src dest

[hadoop_block_not_received_over_threads_quota]
search = hadoop "Not able to receive block" "threads quota is exceeded" 

[hadoop_block_deleted]
search = hadoop "DataNode: Deleted block blk_*" "at file"

[hadoop_block_deleting]
search = hadoop "DataNode: Deleting block blk_*"

[hadoop_block_append]
search = hadoop "Reopen Block for append"

[hadoop_block_scheduling_delete]
search = hadoop "DataNode: Scheduling block blk_*" "for deletion"

[hadoop_block_verification_failed_ok]
search = hadoop "DataBlockScanner: Verification failed for blk_*" "Its ok since"

[hadoop_block_already_exists]
search = hadoop BlockAlreadyExistsException

[hadoop_block_receiver_constructor_exception]
search = hadoop "DataNode: IOException in BlockReceiver constructor"

[hadoop_block_old_new]
search = hadoop DataNode oldblock newblock

[hadoop_block_recover_called]
search = hadoop "calls recoverBlock"

[hadoop_block_cannot_recover]
search = hadoop "IOException: Cannot recover blk_*"

[hadoop_block_update_failed]
search = hadoop "InterDatanodeProtocol: Failed to updateBlock"

[hadoop_block_copied]
search = hadoop "DataNode: Copied block"

[hadoop_block_moved]
search = hadoop "DataNode: Moved block"

[hadoop_block_already_finalized]
search = hadoop "IOException: Block blk_* is already finalized"

[hadoop_block_no_temp_file]
search = hadoop "IOException: No temporary file"

[hadoop_block_no_such_file_dir]
search = hadoop "IOException: No such file or directory"

[hadoop_block_receive_interrupted]
search = hadoop "IOException: Interrupted receiveBlock"

[hadoop_connect_ack_forwarding]
search = hadoop "forwarding connect ack"

[hadoop_connect_ack_received]
search = hadoop "got response for connect ack"

[hadoop_dna_register]
search = hadoop "DNA_REGISTER"

[hadoop_data_node_registration]
search = hadoop DataNode DatanodeRegistration

[hadoop_webhdfs_disabled]
search = hadoop "dfs.webhdfs.enabled = false"

[hadoop_webhdfs_enabled]
search = hadoop "dfs.webhdfs.enabled = true"

[hadoop_info_server_opened]
search = hadoop "Opened info server at"

[hadoop_balancing_bandwidth]
search = hadoop "Balancing bandwith is"

[hadoop_registered_fsdatastatus_mbean]
search = hadoop "Registered FSDatasetStatusMBean"

[hadoop_storage_formatting]
search = hadoop "Storage: Formatting ..."

[hadoop_storage_dir_not_formatted]
search = hadoop "Storage: Storage directory" "is not formatted"

[hadoop_storage_id_assigned_to_node]
search = hadoop "DataNode: New storage id" "is assigned to data-node"

[hadoop_rpc_node_not_available_yet]
search = hadoop "not available yet, Zzzzz..."

[hadoop_incompatible_namespace_id]
search = hadoop "IOException: Incompatible namespaceIDs in"

[hadoop_incompatible_build_versions]
search = hadoop "Incompatible build versions"

[hadoop_shell_could_not_get_disk_info]
search = hadoop "Shell: Could not get disk usage information"

[hadoop_shell_exit_code_exception]
search = hadoop "Shell$ExitCodeException"

[hadoop_waiting_for_thread_group_exit]
search = hadoop "Waiting for threadgroup to exit"

[hadoop_data_node_shutting_down]
search = hadoop "DataNode: DataNode is shutting down"

### rack

[hadoop_adding_node]
search = hadoop "Adding a new node:"

### dfs client

[hadoop_dfs_block_locations_error]
search = hadoop "DFSClient: Could not get block locations"

[hadoop_dfs_error_recovery]
search = hadoop "DFSClient: Error Recovery"

### users 

[hadoop_got_native_user]
search = hadoop "Got UserName" "from the native implementation" 

[hadoop_user_init]
search = hadoop "Initializing user" "on this TT"

[hadoop_uid_cache_init]
search = hadoop "Initialized cache for UID to User mapping"

### distributed cache manager

[hadoop_cached_file_creating]
search = hadoop "TrackerDistributedCacheManager: Creating"

[hadoop_cached_file_extracting]
search = hadoop "TrackerDistributedCacheManager: Extracting"

[hadoop_cached_file_done]
search = hadoop "TrackerDistributedCacheManager: Cached"

### index cache 

[hadoop_map_not_found_in_cache]
search = hadoop map id "not found in cache"

[hadoop_reduce_not_found_in_cache]
search = hadoop reduce id "not found in cache"

### JVM 

[hadoop_jvm_exited_ok]
search = hadoop jvm "exited with exit code 0"

[hadoop_jvm_exited_not_ok]
search = hadoop jvm "exited with exit code" NOT "code 0" 

[hadoop_jvm_given_task]
search = hadoop "jvm with id" "given task" 

[hadoop_jvm_spawned]
search = hadoop jvm runner spawned

[hadoop_jvm_constructed]
search = hadoop "in JvmRunner constructed JVM ID"

[hadoop_jvm_killed]
search = hadoop "Killing JVM"

[hadoop_jvm_removed_not_killed]
search = hadoop "JVM Not killed" "but just removed"

### exceptions

[hadoop_addr_in_use]
search = hadoop "Address already in use"

[hadoop_conn_reset_by_peer]
search = hadoop exception OR IOException "Connection reset by peer"

[hadoop_no_route_to_host]
search = hadoop "No route to host"

[hadoop_lost_task]
search = hadoop "Process Thread Dump: lost task"

[hadoop_connection_refused]
search = hadoop "ConnectException: Connection refused"

[hadoop_no_route_to_host]
search = hadoop "No route to host"

[hadoop_no_such_process]
search = hadoop "Error sending signal" "to process group"

[hadoop_child_error]
search = hadoop "Child error"

[hadoop_disk_error]
search = hadoop DiskErrorException

[hadoop_file_not_found]
search = hadoop FileNotFoundException

[hadoop_index_file_read_error]
search = hadoop "Error Reading IndexFile"

[hadoop_class_not_found]
search = hadoop ClassNotFoundException

[hadoop_end_of_file]
search = hadoop EOFException 

[hadoop_problem_cleaning_dir]
search = hadoop "problem cleaning system directory"

[hadoop_bind_error]
search = hadoop "problem binding to"

[hadoop_oom_error]
search = hadoop OutOfMemoryError

[hadoop_invocation_target_exception]
search = hadoop InvocationTargetException

[hadoop_file_replication_error]
search = hadoop file "could only be replicated to" nodes "instead of"
